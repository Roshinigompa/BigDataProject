{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wpqz7qC2wnD",
        "outputId": "0d46bd13-db61-4cc3-d6d6-5f5104f3eb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hllo\n"
          ]
        }
      ],
      "source": [
        "print(\"Hllo\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-V_a_-E5B2T",
        "outputId": "73e01679-0f4e-482b-db44-1bc18f01324d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "\n",
        "hostname = \"2fydd.h.filess.io\"\n",
        "database = \"olistproject_pigbasemet\"\n",
        "port = \"3307\"\n",
        "username = \"olistproject_pigbasemet\"\n",
        "password = \"cc50138b86496b619eb2ae5e34616ac23408e24a\"\n",
        "\n",
        "try:\n",
        "    connection = mysql.connector.connect(host=hostname, database=database, user=username, password=password, port=port)\n",
        "    if connection.is_connected():\n",
        "        db_Info = connection.get_server_info()\n",
        "        print(\"Connected to MySQL Server version \", db_Info)\n",
        "        cursor = connection.cursor()\n",
        "        cursor.execute(\"select database();\")\n",
        "        record = cursor.fetchone()\n",
        "        print(\"You're connected to database: \", record)\n",
        "\n",
        "except Error as e:\n",
        "    print(\"Error while connecting to MySQL\", e)\n",
        "finally:\n",
        "    if connection.is_connected():\n",
        "        cursor.close()\n",
        "        connection.close()\n",
        "        print(\"MySQL connection is closed\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJeWT0WI4oqh",
        "outputId": "b555e37a-ddc7-4ccf-aed6-3c8ff362c98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-98779340382d>:13: DeprecationWarning: Call to deprecated function get_server_info. Reason: \n",
            "    The property counterpart 'server_info' should be used instead.\n",
            "\n",
            "  db_Info = connection.get_server_info()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to MySQL Server version  8.0.36-28\n",
            "You're connected to database:  ('olistproject_pigbasemet',)\n",
            "MySQL connection is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "order_payments=pd.read_csv(\"/content/sample_data/olist_order_payments_dataset.csv\")\n",
        "order_payments.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "xY458-_65KbM",
        "outputId": "3b89a3e7-f16a-4dad-9a4d-75f8a130a3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/olist_order_payments_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-90568919c2a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0morder_payments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/olist_order_payments_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0morder_payments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/olist_order_payments_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_payments.shape"
      ],
      "metadata": {
        "id": "l805j3h28xc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "\n",
        "# Connection details\n",
        "hostname = \"2fydd.h.filess.io\"\n",
        "database = \"olistproject_pigbasemet\"\n",
        "port = \"3307\"\n",
        "username = \"olistproject_pigbasemet\"\n",
        "password = \"cc50138b86496b619eb2ae5e34616ac23408e24a\"\n",
        "\n",
        "# CSV file path\n",
        "csv_file_path = \"/content/sample_data/olist_order_payments_dataset.csv\"\n",
        "\n",
        "# Table name where the data will be uploaded\n",
        "table_name = \"olist_order_payments\"\n",
        "\n",
        "try:\n",
        "    # Step 1: Establish a connection to MySQL server\n",
        "    connection = mysql.connector.connect(\n",
        "        host=hostname,\n",
        "        database=database,\n",
        "        user=username,\n",
        "        password=password,\n",
        "        port=port\n",
        "    )\n",
        "    if connection.is_connected():\n",
        "        print(\"Connected to MySQL Server successfully!\")\n",
        "\n",
        "        # Step 2: Create a cursor to execute SQL queries\n",
        "        cursor = connection.cursor()\n",
        "\n",
        "        # Step 3: Drop table if it already exists (for clean insertion)\n",
        "        cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
        "        print(f\"Table `{table_name}` dropped if it existed.\")\n",
        "\n",
        "        # Step 4: Create a table structure to match CSV file\n",
        "        create_table_query = f\"\"\"\n",
        "        CREATE TABLE {table_name} (\n",
        "            order_id VARCHAR(50),\n",
        "            payment_sequential INT,\n",
        "            payment_type VARCHAR(20),\n",
        "            payment_installments INT,\n",
        "            payment_value FLOAT\n",
        "        );\n",
        "        \"\"\"\n",
        "        cursor.execute(create_table_query)\n",
        "        print(f\"Table `{table_name}` created successfully!\")\n",
        "\n",
        "        # Step 5: Load the CSV data into pandas DataFrame\n",
        "        data = pd.read_csv(csv_file_path)\n",
        "        print(\"CSV data loaded into pandas DataFrame.\")\n",
        "\n",
        "        # Step 6: Insert data in batches of 500 records\n",
        "        batch_size = 500  # Define the batch size\n",
        "        total_records = len(data)  # Get total records in the DataFrame\n",
        "\n",
        "        print(f\"Starting data insertion into `{table_name}` in batches of {batch_size} records.\")\n",
        "        for start in range(0, total_records, batch_size):\n",
        "            end = start + batch_size\n",
        "            batch = data.iloc[start:end]  # Get the current batch of records\n",
        "\n",
        "            # Convert batch to list of tuples for MySQL insertion\n",
        "            batch_records = [\n",
        "                tuple(row) for row in batch.itertuples(index=False, name=None)\n",
        "            ]\n",
        "\n",
        "            # Prepare the INSERT query\n",
        "            insert_query = f\"\"\"\n",
        "            INSERT INTO {table_name}\n",
        "            (order_id, payment_sequential, payment_type, payment_installments, payment_value)\n",
        "            VALUES (%s, %s, %s, %s, %s);\n",
        "            \"\"\"\n",
        "\n",
        "            # Execute the insertion query for the batch\n",
        "            cursor.executemany(insert_query, batch_records)\n",
        "            connection.commit()  # Commit after each batch\n",
        "            print(f\"Inserted records {start + 1} to {min(end, total_records)} successfully.\")\n",
        "\n",
        "        print(f\"All {total_records} records inserted successfully into `{table_name}`.\")\n",
        "\n",
        "except Error as e:\n",
        "    # Step 7: Handle any errors\n",
        "    print(\"Error while connecting to MySQL or inserting data:\", e)\n",
        "\n",
        "finally:\n",
        "    # Step 8: Close the cursor and connection\n",
        "    if connection.is_connected():\n",
        "        cursor.close()\n",
        "        connection.close()\n",
        "        print(\"MySQL connection is closed.\")\n"
      ],
      "metadata": {
        "id": "TELF2rG46-Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vv73djJMS52",
        "outputId": "79b37e3b-0c4c-467c-93c4-5e648c3a802c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.13.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing module\n",
        "from pymongo import MongoClient\n",
        "\n",
        "hostname = \"xdtqr.h.filess.io\"\n",
        "database = \"olistDataNoSQL_teacherbox\"\n",
        "port = \"61004\"\n",
        "username = \"olistDataNoSQL_teacherbox\"\n",
        "password = \"fcec05230340cf66a26f410a35c9fdaae8852143\"\n",
        "\n",
        "uri = \"mongodb://\" + username + \":\" + password + \"@\" + hostname + \":\" + port + \"/\" + database\n",
        "\n",
        "# Connect with the portnumber and host\n",
        "client = MongoClient(uri)\n",
        "\n",
        "# Access database\n",
        "mydatabase = client[database]\n"
      ],
      "metadata": {
        "id": "Kdr4mF9oMGVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVe-agaIMrFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read the product_category.csv and create a collection and upload to above mangoDb\n",
        "\n",
        "# CSV file path\n",
        "csv_file_path = \"/content/sample_data/product_category_name_translation.csv\"\n",
        "\n",
        "# Collection name where the data will be uploaded\n",
        "collection_name = \"product_category\"\n",
        "\n",
        "try:\n",
        "    # Step 1: Access the database\n",
        "    mydatabase = client[database]\n",
        "    print(f\"Accessed database: {database}\")\n",
        "\n",
        "    # Step 2: Access or create a collection\n",
        "    mycollection = mydatabase[collection_name]\n",
        "    print(f\"Accessed or created collection: {collection_name}\")\n",
        "\n",
        "    # Step 3: Load the CSV data into pandas DataFrame\n",
        "    data = pd.read_csv(csv_file_path)\n",
        "    print(\"CSV data loaded into pandas DataFrame.\")\n",
        "\n",
        "    # Step 4: Convert DataFrame to a list of dictionaries\n",
        "    # MongoDB prefers documents in dictionary format\n",
        "    records = data.to_dict('records')\n",
        "    print(\"DataFrame converted to list of dictionaries.\")\n",
        "\n",
        "    # Step 5: Insert the records into the MongoDB collection\n",
        "    if records:\n",
        "        # Optional: Clear existing data in the collection before inserting\n",
        "        # mycollection.delete_many({})\n",
        "        # print(f\"Cleared existing data in collection `{collection_name}`.\")\n",
        "\n",
        "        result = mycollection.insert_many(records)\n",
        "        print(f\"Inserted {len(result.inserted_ids)} documents into `{collection_name}`.\")\n",
        "    else:\n",
        "        print(\"No data to insert into the collection.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Step 6: Handle any errors\n",
        "    print(\"Error while connecting to MongoDB or inserting data:\", e)\n",
        "\n",
        "finally:\n",
        "    # Step 7: Close the MongoDB connection\n",
        "    if client:\n",
        "        client.close()\n",
        "        print(\"MongoDB connection is closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChR3EhspNieh",
        "outputId": "4f3ad0bf-6479-4b79-f6b4-7b01da314650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessed database: olistDataNoSQL_teacherbox\n",
            "Accessed or created collection: product_category\n",
            "CSV data loaded into pandas DataFrame.\n",
            "DataFrame converted to list of dictionaries.\n",
            "Inserted 71 documents into `product_category`.\n",
            "MongoDB connection is closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: shape of the above product category df\n",
        "\n",
        "# The data for `product_category` was loaded into a pandas DataFrame `data` before being inserted into MongoDB.\n",
        "# We can get the shape of this DataFrame.\n",
        "print(\"Shape of the product_category DataFrame:\")\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQiD0OmbObnP",
        "outputId": "f9ae9de0-e5ed-4eae-bc32-9610628a1aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the product_category DataFrame:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}